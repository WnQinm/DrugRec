{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mimic 疾病处理初步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据icd10大类将mimic中的疾病分类保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "icd9toicd10 = pd.read_csv('icd9toicd10cmgem.csv', usecols=['icd9cm', 'icd10cm'])\n",
    "map9to10 = defaultdict(str)\n",
    "for i in range(len(icd9toicd10)):\n",
    "    icd9 = icd9toicd10.iloc[i]['icd9cm']\n",
    "    icd10 = icd9toicd10.iloc[i]['icd10cm']\n",
    "    while icd9.startswith('0'):\n",
    "        icd9 = icd9[1:]\n",
    "    if len(map9to10[icd9]) == 0 or map9to10[icd9] == 'NoDx':\n",
    "        map9to10[icd9] = icd10\n",
    "np.save('icd9toicd10.npy', map9to10)\n",
    "\n",
    "def get_icd10_type(id: str) -> str:\n",
    "    if id[0] in ['A', 'B']:\n",
    "        return 'Certain infectious and parasitic diseases'\n",
    "    elif id[0] == 'C':\n",
    "        return 'Neoplasms'\n",
    "    elif id[0] == 'D':\n",
    "        if id[1:3].isdecimal() and int(id[1:3]) <= 49:\n",
    "            return 'Neoplasms'\n",
    "        else:\n",
    "            return 'Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism'\n",
    "    elif id[0] == 'E':\n",
    "        return 'Endocrine, nutritional and metabolic diseases'\n",
    "    elif id[0] == 'F':\n",
    "        return 'Mental, Behavioral and Neurodevelopmental disorders'\n",
    "    elif id[0] == 'G':\n",
    "        return 'Diseases of the nervous system'\n",
    "    elif id[0] == 'H':\n",
    "        if id[1:3].isdecimal() and int(id[1:3]) <= 59:\n",
    "            return 'Diseases of the eye and adnexa'\n",
    "        else:\n",
    "            return 'Diseases of the ear and mastoid process'\n",
    "    elif id[0] == 'I':\n",
    "        return 'Diseases of the circulatory system'\n",
    "    elif id[0] == 'J':\n",
    "        return 'Diseases of the respiratory system'\n",
    "    elif id[0] == 'K':\n",
    "        return 'Diseases of the digestive system'\n",
    "    elif id[0] == 'L':\n",
    "        return 'Diseases of the skin and subcutaneous tissue'\n",
    "    elif id[0] == 'M':\n",
    "        return 'Diseases of the musculoskeletal system and connective tissue'\n",
    "    elif id[0] == 'N':\n",
    "        return 'Diseases of the genitourinary system'\n",
    "    elif id[0] == 'O':\n",
    "        return 'Pregnancy, childbirth and the puerperium'\n",
    "    elif id[0] == 'P':\n",
    "        return 'Certain conditions originating in the perinatal period'\n",
    "    elif id[0] == 'Q':\n",
    "        return 'Congenital malformations, deformations and chromosomal abnormalities'\n",
    "    elif id[0] == 'R':\n",
    "        return 'Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified'\n",
    "    elif id[0] in ['S', 'T']:\n",
    "        return 'Injury, poisoning and certain other consequences of external causes'\n",
    "    elif id[0] == 'U':\n",
    "        return 'Codes for special purposes'\n",
    "    elif id[0] in ['V', 'W', 'X', 'Y']:\n",
    "        return 'External causes of morbidity'\n",
    "    elif id[0] == 'Z':\n",
    "        return 'Factors influencing health status and contact with health services'\n",
    "\n",
    "diagnosis = pd.read_csv('diagnosis_icd.csv')\n",
    "all_type = defaultdict(list)\n",
    "for i in tqdm(range(len(diagnosis))):\n",
    "    code, version = diagnosis.iloc[i]['icd_code'], diagnosis.iloc[i]['icd_version']\n",
    "    if version == 9:\n",
    "        code = icd9toicd10[code]\n",
    "    if len(code) == 0 or code == 'NoDx':\n",
    "        continue\n",
    "    all_type[get_icd10_type(code)].append([diagnosis.iloc[i]['subject_id'], diagnosis.iloc[i]['hadm_id']])\n",
    "for k in all_type.keys():\n",
    "    df = pd.DataFrame(all_type[k], columns=['subject_id', 'hadm_id'])\n",
    "    df.to_csv(f'diagnosis/{k}.csv', index=False)\n",
    "    print(k, len(all_type[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取药物相互作用关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "tree = et.parse(\"drugbank_full database.xml\")\n",
    "all_drug = tree.findall(\"drug\")\n",
    "proc = lambda text: text.replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\"\\r\", \"\").strip()\n",
    "DDI = defaultdict(dict)\n",
    "\n",
    "for drug in tqdm(all_drug):\n",
    "    for i in drug.findall(\"drugbank-id\"):\n",
    "        if i.attrib.get(\"primary\", False) == \"true\":\n",
    "            drug_id = proc(i.text)\n",
    "    for di in drug.find(\"drug-interactions\").findall(\"drug-interaction\"):\n",
    "        DDI[drug_id][proc(di.find(\"drugbank-id\").text)] = proc(di.find(\"description\").text)\n",
    "\n",
    "DDI_json = json.dumps(DDI, indent=4)\n",
    "with open(\"./DDI.json\", \"w\") as f:\n",
    "    f.write(DDI_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drugbank中所有的药物及相关信息\n",
    "\n",
    "{drug_id: {\"names\":[names], \"description\":description}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "tree = et.parse(\"drugbank_full database.xml\")\n",
    "all_drug = tree.findall(\"drug\")\n",
    "proc = lambda text: text.replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\"\\r\", \"\").strip()\n",
    "fail = []\n",
    "ans = dict()\n",
    "\n",
    "for drug in tqdm(all_drug):\n",
    "    temp = {\"id\":None, \"name\":None, \"desc\":None}\n",
    "    names = []\n",
    "    # id\n",
    "    for id in drug.findall(\"drugbank-id\"):\n",
    "        if \"primary\" in id.attrib.keys() and id.attrib[\"primary\"]==\"true\":\n",
    "            temp[\"id\"] = id.text\n",
    "            break\n",
    "    if type(temp[\"id\"]) is not str and len(temp[\"id\"]) == 0:\n",
    "        fail.append(drug)\n",
    "        continue\n",
    "    # desc\n",
    "    desc = \"\"\n",
    "    ## description\n",
    "    if drug.find(\"description\").text:\n",
    "        desc += proc(drug.find(\"description\").text)\n",
    "        desc += \"\\n\"\n",
    "    ## indication\n",
    "    if drug.find(\"indication\").text:\n",
    "        desc += proc(drug.find(\"indication\").text)\n",
    "        desc += \"\\n\"\n",
    "    ## products\n",
    "    products = []\n",
    "    for product in drug.find(\"products\").findall(\"product\"):\n",
    "        if product.find(\"name\").text:\n",
    "            p = proc(product.find(\"name\").text)\n",
    "            if p not in names:\n",
    "                names.append(p)\n",
    "        else:\n",
    "            continue\n",
    "        if product.find(\"dosage-form\").text:\n",
    "            p += ' {}'.format(proc(product.find(\"dosage-form\").text).replace(\",\", \"\"))\n",
    "        if product.find(\"strength\").text:\n",
    "            p += ' {}'.format(proc(product.find(\"strength\").text))\n",
    "        if product.find(\"route\").text:\n",
    "            p += ' {}'.format(proc(product.find(\"route\").text))\n",
    "        products.append(p)\n",
    "    if len(products) > 0:\n",
    "        products = \"; \".join(list(set(products)))\n",
    "        products = products[:-2]\n",
    "        desc += products\n",
    "        desc += \"\\n\"\n",
    "    ## food-interactions\n",
    "    fis = \"\"\n",
    "    for fi in drug.find(\"food-interactions\").findall(\"food-interaction\"):\n",
    "        if fi.text:\n",
    "            fis += proc(fi.text)\n",
    "            fis += \"; \"\n",
    "    if len(fis) > 0:\n",
    "        desc += fis[:-2]\n",
    "        desc += \"\\n\"\n",
    "    # name\n",
    "    ## synonyms\n",
    "    for syn in drug.find(\"synonyms\").findall(\"synonym\"):\n",
    "        if syn.attrib.get(\"language\", False) == \"english\":\n",
    "            names.append(proc(syn.text))\n",
    "    ## name\n",
    "    names.append(proc(drug.find(\"name\").text))\n",
    "    temp[\"name\"] = names\n",
    "\n",
    "    temp[\"desc\"] = desc\n",
    "\n",
    "    ans[temp[\"id\"]] = {\"names\":temp[\"name\"], \"description\":temp[\"desc\"]}\n",
    "\n",
    "ans = json.dumps(ans, indent=4)\n",
    "with open(\"drugs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取mimic数据集中循环系统大类中涉及的所有药物"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pres = pd.read_csv(\"./data/prescriptions.csv\", usecols=[\"subject_id\", 'hadm_id', 'drug'])\n",
    "# 60271\n",
    "dcs = pd.read_csv(\"./data/Diseases of the circulatory system.csv\")\n",
    "\n",
    "all_drugs = set()\n",
    "\n",
    "for i in tqdm(range(len(dcs))):\n",
    "    subject_id = dcs.iloc[i][\"subject_id\"]\n",
    "    hadm_id = dcs.iloc[i][\"hadm_id\"]\n",
    "    all_drugs = all_drugs.union(set(pres[(pres[\"subject_id\"] == subject_id) & (pres[\"hadm_id\"] == hadm_id)][\"drug\"].tolist()))\n",
    "\n",
    "all_drugs = list(all_drugs)\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"./data/mimic_drugs.json\", \"w\") as f:\n",
    "    f.write(json.dumps(all_drugs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取药物训练数据（没有ndc数据前）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "爬取mimic药物描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.retriever.bing_retriever import BingRetriever\n",
    "from src.utils.arguments import ModelArguments\n",
    "import json\n",
    "import urllib3\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "with open(\"./data/mimic_drugs_filter.json\", \"r\") as f:\n",
    "    all_drugs: list = json.load(f)\n",
    "\n",
    "r = BingRetriever(ModelArguments(\"./\"))\n",
    "\n",
    "drug_desc = dict()\n",
    "\n",
    "for drug_i, drug in enumerate(tqdm(all_drugs)):\n",
    "    drug_desc[drug] = r(drug)\n",
    "    if drug_i % 100 == 0:\n",
    "        with open(\"./data/mimic_drug_search_results.json\", \"w\") as f:\n",
    "            f.write(json.dumps(drug_desc))\n",
    "\n",
    "with open(\"./data/mimic_drug_search_results.json\", \"w\") as f:\n",
    "    f.write(json.dumps(drug_desc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对搜到的结果太少的药物重爬一遍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from src.retriever.bing_retriever import BingRetriever\n",
    "from src.utils.arguments import ModelArguments\n",
    "import urllib3\n",
    "\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "with open(\"./data/mimic_drug_search_results.json\", \"r\") as f:\n",
    "    drug_desc = json.load(f)\n",
    "\n",
    "r = BingRetriever(ModelArguments(\"./\"))\n",
    "drugs = [k for k,v in drug_desc.items() if len(v) < 50]\n",
    "\n",
    "for drug in tqdm(drugs):\n",
    "    drug_desc[drug] = r(drug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看PDD数据里能用的有多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2137, 3989, 3276, 978)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"./data/mimicdrug2drugbank.json\", \"r\") as f:\n",
    "    mimic2drugbank = json.load(f)\n",
    "\n",
    "with open(\"./data/mimic_drugs.json\", \"r\") as f:\n",
    "    all_drugs = json.load(f)\n",
    "\n",
    "fail = []\n",
    "for drug in all_drugs:\n",
    "    if mimic2drugbank.get(drug, False):\n",
    "        continue\n",
    "    else:\n",
    "        fail.append(drug)\n",
    "\n",
    "with open(\"./data/mimic_drugs_filter.json\", \"w\") as f:\n",
    "    f.write(json.dumps(fail))\n",
    "\n",
    "len(fail), len(all_drugs), len(mimic2drugbank), len(set(mimic2drugbank.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对爬到的药物取topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from src.model.bgem3 import M3ForScore\n",
    "from src.utils.arguments import ModelArguments\n",
    "from transformers import HfArgumentParser\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "with open(\"./data/mimic_drug_search_results.json\", \"r\") as f:\n",
    "    drugs = json.load(f)\n",
    "\n",
    "with torch.no_grad():\n",
    "    parser = HfArgumentParser((ModelArguments, ))\n",
    "    model_args = parser.parse_dict({\"model_path\":\"./checkpoint/m3/\"})[0]\n",
    "    model = M3ForScore(model_args, device=\"cuda\", batch_size=4)\n",
    "\n",
    "    for drug, data_list in tqdm(drugs.items()):\n",
    "        drugs[drug] = model(drug, data_list, 5)\n",
    "\n",
    "with open(\"./data/mimic_drug_desc.json\", \"w\") as f:\n",
    "    f.write(json.dumps(drugs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对drugbank里的药物做嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.bgem3 import M3ForInference\n",
    "from src.utils.arguments import ModelArguments\n",
    "from transformers import HfArgumentParser\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import torch\n",
    "\n",
    "with open(\"./data/drugs.json\") as f:\n",
    "    drugs = json.load(f)\n",
    "\n",
    "with torch.no_grad():\n",
    "    parser = HfArgumentParser((ModelArguments, ))\n",
    "    model_args = parser.parse_dict({\"model_path\":\"./checkpoint/m3/\"})[0]\n",
    "    model = M3ForInference(model_args, device=\"cuda\")\n",
    "\n",
    "    drug_embed = []\n",
    "    drug_embed_id = []\n",
    "    for k,v in drugs.items():\n",
    "        if len(v[\"description\"])>50:\n",
    "            drug_embed.append(v[\"description\"])\n",
    "            drug_embed_id.append(k)\n",
    "\n",
    "    results = []\n",
    "    batch_size = 4\n",
    "    for i in tqdm(range(0, len(drug_embed), batch_size)):\n",
    "        if i+batch_size>=len(drug_embed):\n",
    "            results.append(model(drug_embed[i:]))\n",
    "        else:\n",
    "            results.append(model(drug_embed[i:i+batch_size]))\n",
    "    results = torch.cat(results, dim=0).detach().cpu()\n",
    "\n",
    "torch.save(results, \"./data/drugs_embed.pt\")\n",
    "\n",
    "with open(\"./data/drugs_embed_id.json\", \"w\") as f:\n",
    "    f.write(json.dumps(drug_embed_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对爬取到的mimic的药物描述做嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.bgem3 import M3ForInference\n",
    "from src.utils.arguments import ModelArguments\n",
    "from transformers import HfArgumentParser\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "\n",
    "with open(\"./data/mimic_drug_desc.json\", \"r\") as f:\n",
    "    drugs = json.load(f)\n",
    "\n",
    "with torch.no_grad():\n",
    "    parser = HfArgumentParser((ModelArguments, ))\n",
    "    model_args = parser.parse_dict({\"model_path\":\"./checkpoint/m3/\"})[0]\n",
    "    model = M3ForInference(model_args, device=\"cuda\")\n",
    "\n",
    "    results = []\n",
    "    for k,v in tqdm(drugs.items()):\n",
    "        results.append(model(k+\" \"+v))\n",
    "    results = torch.stack(results, dim=0).detach().cpu()\n",
    "\n",
    "torch.save(results, \"./data/mimic_drugs_embed.pt\")\n",
    "\n",
    "with open(\"./data/mimic_drugs_embed_id.json\", \"w\") as f:\n",
    "    f.write(json.dumps(list(drugs.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据嵌入结果先在mimic内部消歧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 936, 15],\n",
       " [2, 1503, 1209],\n",
       " [8, 2108, 1674],\n",
       " [9, 2017],\n",
       " [14, 1186],\n",
       " [17, 1093, 548],\n",
       " [18, 1433, 36],\n",
       " [19, 855],\n",
       " [22, 2090, 1150, 2022],\n",
       " [27, 157],\n",
       " [29, 485, 1756, 198],\n",
       " [31, 2072],\n",
       " [34, 72, 125],\n",
       " [42, 401],\n",
       " [44, 1461],\n",
       " [48, 317],\n",
       " [51, 1193],\n",
       " [52, 183, 677, 1376],\n",
       " [55, 1181],\n",
       " [59, 1860, 185],\n",
       " [61, 1515],\n",
       " [66, 1243, 734],\n",
       " [71, 1455],\n",
       " [79, 280],\n",
       " [80, 948, 267],\n",
       " [83, 970, 1833, 1749, 1961],\n",
       " [84, 380, 1934, 465],\n",
       " [86, 1041],\n",
       " [91, 1699],\n",
       " [94, 525],\n",
       " [95, 496],\n",
       " [96, 1386],\n",
       " [99, 1593, 1261],\n",
       " [107, 221, 245],\n",
       " [108, 1783],\n",
       " [109, 662],\n",
       " [111, 861],\n",
       " [112, 878, 226, 959],\n",
       " [113, 1114],\n",
       " [114, 1779, 1341, 854],\n",
       " [120, 1949, 371],\n",
       " [128, 259, 1413],\n",
       " [131, 714],\n",
       " [132, 1887],\n",
       " [136, 254, 1780],\n",
       " [137, 1814],\n",
       " [139, 1322, 638, 414, 1459, 1830],\n",
       " [140, 2097, 1992],\n",
       " [144, 421],\n",
       " [148, 543],\n",
       " [150, 448, 1154],\n",
       " [152, 1197],\n",
       " [154, 408],\n",
       " [155, 1538, 1405, 1358, 804],\n",
       " [164, 1208],\n",
       " [165, 1778, 1384, 708, 1144, 1942, 1567],\n",
       " [166, 1836],\n",
       " [170, 972, 1912],\n",
       " [172, 1669, 1451],\n",
       " [174, 276, 198, 1667],\n",
       " [177, 1014],\n",
       " [178, 990, 794],\n",
       " [186, 717, 1130, 271, 1391, 1204, 760, 469, 1297],\n",
       " [187, 1826, 1221],\n",
       " [189, 938, 2007],\n",
       " [195, 761],\n",
       " [201, 836],\n",
       " [203, 945],\n",
       " [210, 236],\n",
       " [212, 1203],\n",
       " [217, 508, 474, 1200, 351],\n",
       " [219, 1943, 301],\n",
       " [222, 802, 1251],\n",
       " [227, 1390],\n",
       " [231, 1718, 1274],\n",
       " [234, 1552],\n",
       " [238, 852, 371, 1949, 1310],\n",
       " [240, 1803],\n",
       " [248, 384],\n",
       " [250, 2006],\n",
       " [251, 703, 953],\n",
       " [257, 799, 911],\n",
       " [260, 599],\n",
       " [261, 683, 1067],\n",
       " [262, 1454],\n",
       " [263, 1231],\n",
       " [264, 440],\n",
       " [268, 1035, 254, 1780],\n",
       " [269, 330],\n",
       " [274, 391, 1411, 1956, 1211],\n",
       " [275, 732],\n",
       " [282, 1924, 881, 1289],\n",
       " [284, 361, 2064],\n",
       " [290, 1852],\n",
       " [291, 1643, 754],\n",
       " [295, 1436],\n",
       " [305, 1059],\n",
       " [311, 1054],\n",
       " [315, 435],\n",
       " [322, 1946],\n",
       " [323, 462],\n",
       " [331, 1496],\n",
       " [332, 1208],\n",
       " [339, 867],\n",
       " [342, 726],\n",
       " [346, 1317],\n",
       " [347, 935, 1589],\n",
       " [355, 1810, 1895, 1952],\n",
       " [366, 1025],\n",
       " [372, 1222],\n",
       " [378, 458, 509, 1842, 977],\n",
       " [379, 1108],\n",
       " [382, 818, 1234],\n",
       " [390, 1354],\n",
       " [395, 900, 526],\n",
       " [397, 1166],\n",
       " [402, 870, 1090, 832],\n",
       " [406, 457, 538],\n",
       " [409, 587],\n",
       " [422, 655],\n",
       " [423, 1246, 1554, 1529, 558, 1078, 1449],\n",
       " [424, 1661, 1812, 2062, 1172],\n",
       " [431, 1732],\n",
       " [434, 495],\n",
       " [442, 1527],\n",
       " [443, 1450],\n",
       " [444, 1524],\n",
       " [449, 566, 1832, 633],\n",
       " [452, 1536],\n",
       " [456, 904, 1432],\n",
       " [461, 607, 1178, 584],\n",
       " [463, 486],\n",
       " [472, 806, 1831],\n",
       " [473, 1861],\n",
       " [475, 1757, 1254],\n",
       " [476, 999],\n",
       " [477, 930],\n",
       " [479, 1744],\n",
       " [480, 1959],\n",
       " [482, 826, 1807],\n",
       " [501, 1829, 1028, 1471],\n",
       " [505, 753, 1097],\n",
       " [506, 1627],\n",
       " [507, 918, 993],\n",
       " [510, 758],\n",
       " [511, 1476, 1352, 1492],\n",
       " [519, 845],\n",
       " [520, 733, 1945, 758],\n",
       " [522, 1566],\n",
       " [523, 1940],\n",
       " [524, 600],\n",
       " [528, 1408, 1981],\n",
       " [534, 956],\n",
       " [545, 1827],\n",
       " [553, 2100],\n",
       " [557, 1304],\n",
       " [559, 614, 2018],\n",
       " [561, 1758],\n",
       " [563, 1741],\n",
       " [567, 1594],\n",
       " [570, 1893, 2068],\n",
       " [576, 1042],\n",
       " [577, 647],\n",
       " [586, 1176],\n",
       " [588, 613],\n",
       " [589, 1916, 1969, 1780, 2031, 254],\n",
       " [593, 1994, 664, 1210, 1797, 1014],\n",
       " [594, 1618],\n",
       " [602, 1965],\n",
       " [604, 462, 2098],\n",
       " [608, 820, 1773],\n",
       " [618, 845],\n",
       " [620, 1484, 1834],\n",
       " [624, 1215],\n",
       " [634, 1136],\n",
       " [639, 1959],\n",
       " [640, 1681],\n",
       " [641, 1879],\n",
       " [642, 1282, 1645],\n",
       " [663, 819],\n",
       " [666, 1970, 1717],\n",
       " [667, 1948, 2039],\n",
       " [673, 702],\n",
       " [680, 1475],\n",
       " [682, 1855],\n",
       " [684, 1284],\n",
       " [699, 1645, 1022, 1282],\n",
       " [700, 1039],\n",
       " [701, 1164],\n",
       " [721, 1387],\n",
       " [723, 1199, 1786],\n",
       " [725, 1924, 1426, 1289, 881],\n",
       " [728, 2013],\n",
       " [731, 765],\n",
       " [739, 1092],\n",
       " [742, 962],\n",
       " [744, 849],\n",
       " [748, 1793],\n",
       " [752, 1100],\n",
       " [773, 1418],\n",
       " [780, 1157],\n",
       " [784, 1393],\n",
       " [787, 1621],\n",
       " [788, 1482],\n",
       " [803, 965, 976],\n",
       " [807, 1671],\n",
       " [810, 1395],\n",
       " [814, 931, 2057],\n",
       " [823, 1050],\n",
       " [824, 1533],\n",
       " [830, 1912, 972],\n",
       " [833, 1894, 1241],\n",
       " [840, 1695],\n",
       " [857, 1848],\n",
       " [864, 1907],\n",
       " [868, 896],\n",
       " [869, 1920],\n",
       " [874, 1442],\n",
       " [880, 1983],\n",
       " [883, 2079],\n",
       " [893, 961, 1571, 1118],\n",
       " [895, 1275, 1315],\n",
       " [899, 2025],\n",
       " [909, 958],\n",
       " [916, 1001],\n",
       " [921, 2046],\n",
       " [939, 1259],\n",
       " [943, 1723],\n",
       " [946, 870],\n",
       " [954, 1061, 1446],\n",
       " [967, 1817],\n",
       " [975, 1295],\n",
       " [985, 1774, 1692],\n",
       " [998, 1355],\n",
       " [1004, 2104],\n",
       " [1006, 1562, 2047, 1602],\n",
       " [1008, 2099],\n",
       " [1011, 1458],\n",
       " [1030, 1252],\n",
       " [1048, 1309, 1727],\n",
       " [1052, 2103],\n",
       " [1060, 2080],\n",
       " [1063, 1668],\n",
       " [1071, 1080],\n",
       " [1072, 881],\n",
       " [1074, 1125],\n",
       " [1079, 1080],\n",
       " [1084, 1700, 1128, 1600],\n",
       " [1086, 1477],\n",
       " [1113, 1420],\n",
       " [1116, 1163],\n",
       " [1129, 1925],\n",
       " [1135, 1816],\n",
       " [1140, 1558, 1954],\n",
       " [1149, 1647],\n",
       " [1160, 1441],\n",
       " [1162, 1424],\n",
       " [1169, 1899, 1754],\n",
       " [1196, 1526],\n",
       " [1206, 1257],\n",
       " [1218, 2043, 1401, 1493],\n",
       " [1220, 1728],\n",
       " [1230, 1825, 1958],\n",
       " [1244, 1973],\n",
       " [1245, 1452, 1898],\n",
       " [1249, 1732],\n",
       " [1250, 1371],\n",
       " [1253, 495, 1641],\n",
       " [1266, 1908],\n",
       " [1270, 1687],\n",
       " [1277, 1616],\n",
       " [1283, 1035],\n",
       " [1292, 1843, 976],\n",
       " [1312, 2016],\n",
       " [1314, 1349],\n",
       " [1316, 1354],\n",
       " [1319, 2029],\n",
       " [1326, 2093, 1416],\n",
       " [1328, 1689, 1662],\n",
       " [1330, 1850],\n",
       " [1334, 1591],\n",
       " [1335, 1405],\n",
       " [1336, 1932],\n",
       " [1337, 1605],\n",
       " [1366, 1738, 226, 959],\n",
       " [1370, 1497],\n",
       " [1378, 1755],\n",
       " [1385, 1508],\n",
       " [1394, 1376],\n",
       " [1402, 1781],\n",
       " [1410, 2086],\n",
       " [1415, 1522],\n",
       " [1419, 1813],\n",
       " [1428, 1641],\n",
       " [1430, 1078, 558, 1449],\n",
       " [1445, 1737],\n",
       " [1463, 930],\n",
       " [1466, 2078],\n",
       " [1489, 1842, 458],\n",
       " [1494, 2012, 1234],\n",
       " [1498, 1995],\n",
       " [1500, 1501],\n",
       " [1502, 1895],\n",
       " [1547, 1590],\n",
       " [1550, 2107],\n",
       " [1560, 1685],\n",
       " [1585, 1622],\n",
       " [1607, 1627],\n",
       " [1611, 2034],\n",
       " [1665, 1770],\n",
       " [1678, 1767],\n",
       " [1721, 1025],\n",
       " [1730, 1275, 1315],\n",
       " [1759, 1757, 1254],\n",
       " [1771, 1454],\n",
       " [1805, 1144, 1384],\n",
       " [1835, 2095],\n",
       " [1846, 1862],\n",
       " [1873, 440],\n",
       " [1936, 2111],\n",
       " [1968, 2032],\n",
       " [2024, 2083],\n",
       " [2091, 1834]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "mimic_drugs = torch.load(\"./data/mimic_drugs_embed.pt\").numpy()\n",
    "with open(\"./data/mimic_drugs_embed_id.json\", \"r\") as f:\n",
    "    mimic_drugs_id = np.array(json.load(f))\n",
    "\n",
    "index = faiss.IndexFlatIP(mimic_drugs.shape[-1])\n",
    "index.add(mimic_drugs)\n",
    "# print(index.ntotal)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "D, I = index.search(mimic_drugs, 10)\n",
    "\n",
    "sim_drug = []\n",
    "all_sim_drug = []\n",
    "for idx, (d, i) in enumerate(zip(D, I)):\n",
    "    sim = mimic_drugs_id[i[d>0.85]][1:]\n",
    "    if len(sim) > 0 and idx not in all_sim_drug:\n",
    "        sim_drug.append(i[d>0.85].tolist())\n",
    "        all_sim_drug.extend(i[d>0.85].tolist())\n",
    "sim_drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Aspiri', 'aspi', 'Aspirin 81mg TAB', 'Aspirin 81mg',\n",
       "       'Aspirin 81mg (1cap)', 'Aspirin 325 mg', 'Aspirin 325mg', 'Aspir',\n",
       "       'Aspirin 325'], dtype='<U84')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mimic_drugs_id[[186, 717, 1130, 271, 1391, 1204, 760, 469, 1297]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mimic-drugbank药物对齐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "drugbank_drugs = torch.load(\"./data/drugs_embed.pt\").numpy()\n",
    "with open(\"./data/drugs_embed_id.json\", \"r\") as f:\n",
    "    drugbank_drugs_id = json.load(f)\n",
    "\n",
    "index = faiss.IndexFlatIP(drugbank_drugs.shape[-1])\n",
    "index.add(drugbank_drugs)\n",
    "# print(index.ntotal)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "D, I = index.search(mimic_drugs, 1)\n",
    "D = D.squeeze()\n",
    "I = I.squeeze()\n",
    "\n",
    "for sd in sim_drug:\n",
    "    if 142 in I[sd]:\n",
    "        print(sd, I[sd], D[sd])\n",
    "    I[sd] = I[sd][np.argmax(D[sd])]\n",
    "    D[sd] = np.max(D[sd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 - 1.0   0.03\n",
      "0.8 - 0.9   0.22\n",
      "0.7 - 0.8   0.41\n",
      "0.6 - 0.7   0.31\n",
      "0.0 - 0.6   0.03\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\\n",
    "0.9 - 1.0   {np.sum(D>0.9)/len(D):.2f}\\n\\\n",
    "0.8 - 0.9   {np.sum((D>0.8) & (D<0.9))/len(D):.2f}\\n\\\n",
    "0.7 - 0.8   {np.sum((D>0.7) & (D<0.8))/len(D):.2f}\\n\\\n",
    "0.6 - 0.7   {np.sum((D>0.6) & (D<0.7))/len(D):.2f}\\n\\\n",
    "0.0 - 0.6   {np.sum(D<0.6)/len(D):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mimic to drugbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8019553772875407"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"./data/mimicdrug2drugbank.json\", \"r\") as f:\n",
    "    PDD_map = json.load(f)\n",
    "with open(\"./data/mimic_drugs.json\", \"r\") as f:\n",
    "    all_drugs = json.load(f)\n",
    "\n",
    "mimic2drugbank = dict()\n",
    "for drug in all_drugs:\n",
    "    if PDD_map.get(drug, False):\n",
    "        mimic2drugbank[drug] = PDD_map[drug]\n",
    "\n",
    "\n",
    "threshold = lambda x: x>0.7\n",
    "\n",
    "for idx, (d,i) in enumerate(zip(D, I)):\n",
    "    if threshold(d):\n",
    "        mimic2drugbank[mimic_drugs_id[idx]] = drugbank_drugs_id[i]\n",
    "\n",
    "with open(\"./data/mimicdrug2drugbank.json\", \"w\") as f:\n",
    "    f.write(json.dumps(mimic2drugbank))\n",
    "\n",
    "len(mimic2drugbank) / len(all_drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDD里面有5个旧drugbank数据库中现已弃用的数据，手动查线上drugbank对应一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/mimicdrug2drugbank.json\", \"r\") as f:\n",
    "    drugs = json.load(f)\n",
    "for k,v in drugs.items():\n",
    "    if v == \"DB11122\":\n",
    "        drugs[k] = \"DB09255\"\n",
    "    if v == \"DB09396\":\n",
    "        drugs[k] = \"DB00647\"\n",
    "    if v == \"DB09323\":\n",
    "        drugs[k] = \"DB01053\"\n",
    "    if v == \"DB00021\":\n",
    "        drugs[k] = \"DB09532\"\n",
    "    if v == \"DB11280\":\n",
    "        drugs[k] = \"DB01914\"\n",
    "with open(\"./data/mimicdrug2drugbank.json\", \"w\") as f:\n",
    "    f.write(json.dumps(drugs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把drugbank中要用的药物筛出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./mimicdrug2drugbank.json\", \"r\") as f:\n",
    "    drugs = list(set(json.load(f).values()))\n",
    "\n",
    "with open(\"./drugs.json\", \"r\") as f:\n",
    "    drugbank_drugs = json.load(f)\n",
    "\n",
    "drugbank_drugs_filtered = {}\n",
    "for d in drugs:\n",
    "    if drugbank_drugs[d][\"description\"]:\n",
    "        drugbank_drugs_filtered[d] = drugbank_drugs[d]\n",
    "\n",
    "with open(\"./drugs_filtered.json\", \"w\") as f:\n",
    "    f.write(json.dumps(dict(sorted(drugbank_drugs_filtered.items(), key=lambda obj: obj[0][2:]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取药物训练数据（使用ndc数据）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照其代码处理prescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "med = pres = pd.read_csv(\"./raw_data/prescriptions.csv\", usecols=['subject_id', 'hadm_id', 'drug', 'ndc'])\n",
    "\n",
    "def ndc_meds(med:pd.DataFrame, mapping:str, use_map_cols=None) -> pd.DataFrame:\n",
    "    med.ndc = med.ndc.fillna(-1)\n",
    "    med.ndc = med.ndc.astype(\"Int64\")\n",
    "\n",
    "    def to_str(ndc):\n",
    "        if ndc < 0:\n",
    "            return np.nan\n",
    "        ndc = str(ndc)\n",
    "        return ((\"0\"*(11 - len(ndc))) + ndc)[0:-2]\n",
    "\n",
    "    def format_ndc_table(ndc):\n",
    "        parts = ndc.split(\"-\")\n",
    "        return (\"0\"*(5 - len(parts[0])) + parts[0]) + (\"0\"*(4 - len(parts[1])) + parts[1])\n",
    "\n",
    "    def read_ndc_mapping2(map_path):\n",
    "        ndc_map = pd.read_csv(map_path, encoding = 'latin1')\n",
    "        ndc_map.columns = list(map(str.lower, ndc_map.columns))\n",
    "        return ndc_map\n",
    "\n",
    "    ndc_map = read_ndc_mapping2(mapping)\n",
    "    if use_map_cols:\n",
    "        ndc_map = ndc_map[use_map_cols]\n",
    "\n",
    "    ndc_map['new_ndc'] = ndc_map.productndc.apply(format_ndc_table)\n",
    "    ndc_map.drop_duplicates(subset=['new_ndc'], inplace=True)\n",
    "    med['new_ndc'] = med.ndc.apply(to_str)\n",
    "\n",
    "    med = med.merge(ndc_map, how='inner', left_on='new_ndc', right_on='new_ndc')\n",
    "    return med\n",
    "\n",
    "med = ndc_meds(med, \"./MIMIC-IV-Data-Pipeline/utils/mappings/NDC_product_table.csv\",\n",
    "               ['productndc', 'proprietaryname', 'nonproprietaryname', 'substancename']\n",
    "               )[[\"subject_id\", \"hadm_id\", 'proprietaryname', 'nonproprietaryname', 'substancename']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med.to_csv(\"./mimic_drugs.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取出指定疾病的所有能用于搜索的药物名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "mimic_drugs = pd.read_csv(\"./mimic_drugs.csv\")\n",
    "with open(\"./drugs.json\", \"r\") as f:\n",
    "    drugs = json.load(f)\n",
    "for k,v in drugs.items():\n",
    "    drugs[k] = [d.strip().lower() for d in v[\"names\"]]\n",
    "\n",
    "filtered_diagnosis = pd.read_csv(\"./raw_data/Diseases of the circulatory system.csv\")\n",
    "filtered_mimic_drugs = pd.merge(filtered_diagnosis, mimic_drugs, how='left', on=[\"subject_id\", \"hadm_id\"])\n",
    "\n",
    "\n",
    "fail = []\n",
    "results = dict()\n",
    "\n",
    "for row_i in tqdm(range(len(filtered_mimic_drugs))):\n",
    "    row = filtered_mimic_drugs.iloc[row_i]\n",
    "    names = []\n",
    "    for k in [\"proprietaryname\", \"nonproprietaryname\", \"substancename\"]:\n",
    "        if pd.notna(row[k]):\n",
    "            names.extend(row[k].strip().lower().split(\";\"))\n",
    "    names = list(set(names))\n",
    "    ans = None\n",
    "    for name in names:\n",
    "        if ans:\n",
    "            break\n",
    "        for k,v in drugs.items():\n",
    "            if name in v:\n",
    "                ans = k\n",
    "                break\n",
    "    if not ans:\n",
    "        fail.append(row_i)\n",
    "    else:\n",
    "        results[row_i] = ans\n",
    "\n",
    "with open(\"mimic2drugbank.json\", \"w\") as f:\n",
    "    f.write(json.dumps(results))\n",
    "with open(\"mimic2drugbank_fail.json\", \"w\") as f:\n",
    "    f.write(json.dumps(fail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在循环系统疾病数据中有4739条数据(0.3%)没有处方数据，可能就是单纯没开药"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将结果合并到疾病的表中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open(\"mimic2drugbank.json\", \"r\") as f:\n",
    "    results:dict = json.load(f)\n",
    "\n",
    "mimic_drugs = pd.read_csv(\"./mimic_drugs.csv\")\n",
    "filtered_diagnosis = pd.read_csv(\"./raw_data/Diseases of the circulatory system.csv\")\n",
    "filtered_mimic_drugs = pd.merge(filtered_diagnosis, mimic_drugs, how='left', on=[\"subject_id\", \"hadm_id\"])\n",
    "\n",
    "for i in range(len(filtered_mimic_drugs)):\n",
    "    if not results.get(str(i), False):\n",
    "        results[str(i)] = np.nan\n",
    "for i in (set(range(len(filtered_mimic_drugs))) - set(map(int, results.keys()))):\n",
    "    results[i] = np.nan\n",
    "k,v = zip(*sorted({int(k):v for k,v in results.items()}.items()))\n",
    "filtered_mimic_drugs[\"drug_with_drugbank_id\"] = v\n",
    "filtered_mimic_drugs.to_csv(\"./diseases_circulatory_system_with_drugbank_id.csv\",\n",
    "                            index=False,\n",
    "                            columns=[\"subject_id\", \"hadm_id\", \"drug_with_drugbank_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把要用的药物描述择出来保存下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "with open(\"./drugs.json\", \"r\") as f:\n",
    "    drugs = json.load(f)\n",
    "mimic_drugs = list(set(pd.read_csv(\"./diseases_circulatory_system_with_drugbank_id.csv\")[\"drug_with_drugbank_id\"].tolist()))\n",
    "drugs_filtered = dict()\n",
    "\n",
    "for d in mimic_drugs:\n",
    "    if not pd.isna(d):\n",
    "        drugs_filtered[d] = drugs[d]\n",
    "\n",
    "drugs_filtered = dict(sorted(drugs_filtered.items()))\n",
    "with open(\"./drugs_filtered.json\", \"w\") as f:\n",
    "    f.write(json.dumps(drugs_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 药物知识图谱-边训练数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改药物相互作用关系为能够用datasets加载的知识图谱的边数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c2ce347e4e4353992468df37f20973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/759 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03820816864295125\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "with open(\"./DDI.json\", \"r\") as f:\n",
    "    ddi:Dict[str, Dict[str, str]] = json.load(f)\n",
    "with open(\"./drugs_filtered.json\", \"r\") as f:\n",
    "    drugs:List[str] = json.load(f).keys()\n",
    "\n",
    "links = defaultdict(str)\n",
    "fails = []\n",
    "for head in tqdm(drugs):\n",
    "    if ddi.get(head, False):\n",
    "        for tail, desc in ddi[head].items():\n",
    "            if (tail in drugs) and (not links[tuple(sorted((head, tail)))]):\n",
    "                links[tuple(sorted((head, tail)))] = desc\n",
    "    else:\n",
    "        fails.append(head)\n",
    "print(len(fails)/len(drugs))\n",
    "\n",
    "with open(\"./links.json\", \"w\") as f:\n",
    "    f.write(json.dumps([{\"entity1\":k[0], \"entity2\":k[1], \"description\":v} for k, v in links.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行utils/hn_mine.py生成neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import json\n",
    "\n",
    "def _load_json(file_path) -> dict:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "drug_data = _load_json(\"./drugs_filtered.json\")\n",
    "pos2neg = _load_json(\"./drugs_neg.json\")\n",
    "link_data = datasets.load_dataset(\"json\", data_files=\"./links.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ['Refludan',\n",
       "  'Hirudin variant-1',\n",
       "  'Lepirudin recombinant',\n",
       "  '[Leu1, Thr2]-63-desulfohirudin',\n",
       "  'Lepirudin',\n",
       "  'Desulfatohirudin',\n",
       "  'R-hirudin'],\n",
       " 'description': 'Lepirudin is a recombinant hirudin formed by 65 amino acids that acts as a highly specific and direct thrombin inhibitor.[L41539,L41569] Natural hirudin is an endogenous anticoagulant found in _Hirudo medicinalis_ leeches.[L41539] Lepirudin is produced in yeast cells and is identical to natural hirudin except for the absence of sulfate on the tyrosine residue at position 63 and the substitution of leucine for isoleucine at position 1 (N-terminal end).[A246609] Lepirudin is used as an anticoagulant in patients with heparin-induced thrombocytopenia (HIT), an immune reaction associated with a high risk of thromboembolic complications.[A3, L41539] HIT is caused by the expression of immunoglobulin G (IgG) antibodies that bind to the complex formed by heparin and platelet factor 4. This activates endothelial cells and platelets and enhances the formation of thrombi.[A246609] Bayer ceased the production of lepirudin (Refludan) effective May 31, 2012.[L41574]\\nLepirudin is indicated for anticoagulation in adult patients with acute coronary syndromes (ACS) such as unstable angina and acute myocardial infarction without ST elevation. In patients with ACS, lepirudin is intended for use with [aspirin].[L41539] Lepirudin is also indicated for anticoagulation in patients with heparin-induced thrombocytopenia (HIT) and associated thromboembolic disease in order to prevent further thromboembolic complications.[L41539]\\nRefludan Powder 50 mg/1mL Intravenous; Refludan Powder for solution 50 mg / vial Intravenous; Refludan Injection solution concentrate 50 mg Intravenous; Refludan Injection solution concentrate 20 mg Intraveno\\nAvoid herbs and supplements with anticoagulant/antiplatelet activity. Examples include chamomile, garlic, ginger, ginkgo and ginseng.\\n'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_data[\"DB00001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DB06812',\n",
       " 'DB01363',\n",
       " 'DB01211',\n",
       " 'DB00478',\n",
       " 'DB00184',\n",
       " 'DB00140',\n",
       " 'DB09512',\n",
       " 'DB00736',\n",
       " 'DB00796',\n",
       " 'DB01001',\n",
       " 'DB01075',\n",
       " 'DB00669',\n",
       " 'DB00216',\n",
       " 'DB10317',\n",
       " 'DB00271']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos2neg[\"DB00001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity2': 'DB06605',\n",
       " 'entity1': 'DB00001',\n",
       " 'description': 'Apixaban may increase the anticoagulant activities of Lepirudin.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mimic 训练数据 疾病-药物"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>text</th>\n",
       "      <th>drug_with_drugbank_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11000566</td>\n",
       "      <td>28693615</td>\n",
       "      <td>\\nName:  ___            ___ No:   ___\\n \\nAdm...</td>\n",
       "      <td>DB00316,DB06605,DB01015,DB00332,DB00653,DB0065...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11000680</td>\n",
       "      <td>27035960</td>\n",
       "      <td>\\nName:  ___                      Unit No:   ...</td>\n",
       "      <td>DB01390,DB09020,DB09153,DB00327,DB00818,DB0092...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000722</td>\n",
       "      <td>24717411</td>\n",
       "      <td>\\nName:  ___                 Unit No:   ___\\n...</td>\n",
       "      <td>DB01234,DB00213,DB01109,DB09020,DB00264,DB0123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11000743</td>\n",
       "      <td>24317015</td>\n",
       "      <td>\\nName:  ___                Unit No:   ___\\n ...</td>\n",
       "      <td>DB01164,DB01606,DB09153,DB09413,DB00332,DB0050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11000743</td>\n",
       "      <td>29132287</td>\n",
       "      <td>\\nName:  ___                Unit No:   ___\\n ...</td>\n",
       "      <td>DB09153,DB00512,DB00451,DB09153,DB09020,DB0064...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id                                               text  \\\n",
       "0    11000566  28693615   \\nName:  ___            ___ No:   ___\\n \\nAdm...   \n",
       "1    11000680  27035960   \\nName:  ___                      Unit No:   ...   \n",
       "2    11000722  24717411   \\nName:  ___                 Unit No:   ___\\n...   \n",
       "3    11000743  24317015   \\nName:  ___                Unit No:   ___\\n ...   \n",
       "4    11000743  29132287   \\nName:  ___                Unit No:   ___\\n ...   \n",
       "\n",
       "                               drug_with_drugbank_id  \n",
       "0  DB00316,DB06605,DB01015,DB00332,DB00653,DB0065...  \n",
       "1  DB01390,DB09020,DB09153,DB00327,DB00818,DB0092...  \n",
       "2  DB01234,DB00213,DB01109,DB09020,DB00264,DB0123...  \n",
       "3  DB01164,DB01606,DB09153,DB09413,DB00332,DB0050...  \n",
       "4  DB09153,DB00512,DB00451,DB09153,DB09020,DB0064...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载带drugbank药物数据的mimic数据 去除空值\n",
    "drugs = pd.read_csv(\"./data/diseases_circulatory_system_with_drugbank_id.csv\")\n",
    "drugs = drugs[~drugs.isna()]\n",
    "drugs[\"drug_with_drugbank_id\"] = drugs[\"drug_with_drugbank_id\"].astype('str')\n",
    "\n",
    "# 每次就诊时医生开出的所有药物数据聚集在一行里\n",
    "mimic_data = drugs.groupby([\"subject_id\", \"hadm_id\"])[\"drug_with_drugbank_id\"].agg(lambda x: ','.join(x))\n",
    "discharge = pd.read_csv(\"./data/mimic-note/discharge.csv\", usecols=[\"subject_id\", \"hadm_id\", \"text\"])\n",
    "# 将症状描述表和开药数据表通过就诊id连接\n",
    "mimic_with_text = pd.merge(discharge, right=mimic_data, how='right', on=[\"subject_id\", \"hadm_id\"])\n",
    "# 去除空值\n",
    "traindata = mimic_with_text[(~mimic_with_text.text.isna()) & (~mimic_with_text.drug_with_drugbank_id.isna())].reset_index(drop=True)\n",
    "traindata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChiefComplaint空值占比 0.012735589424336174\n",
      "HistoryOfPresentIllness空值占比 0.019017974073300813\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>drug_with_drugbank_id</th>\n",
       "      <th>ChiefComplaint</th>\n",
       "      <th>HistoryOfPresentIllness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11000566</td>\n",
       "      <td>28693615</td>\n",
       "      <td>DB00316,DB06605,DB01015,DB00332,DB00653,DB0065...</td>\n",
       "      <td>Cold symptoms, shortness of breath</td>\n",
       "      <td>Ms. ___ is a ___ year old female with hx of NP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11000680</td>\n",
       "      <td>27035960</td>\n",
       "      <td>DB01390,DB09020,DB09153,DB00327,DB00818,DB0092...</td>\n",
       "      <td>found down</td>\n",
       "      <td>HPI: Patient is a ___ with complex medical his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000722</td>\n",
       "      <td>24717411</td>\n",
       "      <td>DB01234,DB00213,DB01109,DB09020,DB00264,DB0123...</td>\n",
       "      <td>___ with right ventricular mass</td>\n",
       "      <td>Mr. ___ is a ___ y/o male with no prior past m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11000743</td>\n",
       "      <td>24317015</td>\n",
       "      <td>DB01164,DB01606,DB09153,DB09413,DB00332,DB0050...</td>\n",
       "      <td>respiratory distress</td>\n",
       "      <td>___ yo M w/ h/o Down's syndrome, non-verbal at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11000743</td>\n",
       "      <td>29132287</td>\n",
       "      <td>DB09153,DB00512,DB00451,DB09153,DB09020,DB0064...</td>\n",
       "      <td>cough, respiratory distress</td>\n",
       "      <td>___ yo M w/ h/o Down's syndrome, non-verbal at...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id                              drug_with_drugbank_id  \\\n",
       "0    11000566  28693615  DB00316,DB06605,DB01015,DB00332,DB00653,DB0065...   \n",
       "1    11000680  27035960  DB01390,DB09020,DB09153,DB00327,DB00818,DB0092...   \n",
       "2    11000722  24717411  DB01234,DB00213,DB01109,DB09020,DB00264,DB0123...   \n",
       "3    11000743  24317015  DB01164,DB01606,DB09153,DB09413,DB00332,DB0050...   \n",
       "4    11000743  29132287  DB09153,DB00512,DB00451,DB09153,DB09020,DB0064...   \n",
       "\n",
       "                       ChiefComplaint  \\\n",
       "0  Cold symptoms, shortness of breath   \n",
       "1                          found down   \n",
       "2     ___ with right ventricular mass   \n",
       "3                respiratory distress   \n",
       "4         cough, respiratory distress   \n",
       "\n",
       "                             HistoryOfPresentIllness  \n",
       "0  Ms. ___ is a ___ year old female with hx of NP...  \n",
       "1  HPI: Patient is a ___ with complex medical his...  \n",
       "2  Mr. ___ is a ___ y/o male with no prior past m...  \n",
       "3  ___ yo M w/ h/o Down's syndrome, non-verbal at...  \n",
       "4  ___ yo M w/ h/o Down's syndrome, non-verbal at...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def extract_data(text:str):\n",
    "    ChiefComplaint = re.findall(r\"[ \\n]+(Chief|___) Complaint:\\n(.*)?[ \\n]+\", text, re.IGNORECASE)\n",
    "    if len(ChiefComplaint) != 1:\n",
    "        ChiefComplaint = np.nan\n",
    "    else:\n",
    "        ChiefComplaint = ChiefComplaint[0][1].strip()\n",
    "    HistoryOfPresentIllness = re.findall(r\"History of Present Illness:([\\s\\S]*)?Past Medical History\", text, re.IGNORECASE)\n",
    "    if len(HistoryOfPresentIllness) != 1:\n",
    "        HistoryOfPresentIllness = np.nan\n",
    "    else:\n",
    "        HistoryOfPresentIllness = HistoryOfPresentIllness[0].replace(\"\\n\", \"\").strip()\n",
    "        HistoryOfPresentIllness = re.sub(r\"\\s+\", \" \", HistoryOfPresentIllness)\n",
    "    return ChiefComplaint, HistoryOfPresentIllness\n",
    "\n",
    "# 提取主诉和现病史\n",
    "results = traindata.text.apply(extract_data)\n",
    "ChiefComplaint, HistoryOfPresentIllness = zip(*results.tolist())\n",
    "print(\"ChiefComplaint空值占比\", sum(list(map(lambda x:type(x)!=str, ChiefComplaint)))/len(ChiefComplaint))\n",
    "print(\"HistoryOfPresentIllness空值占比\", sum(list(map(lambda x:type(x)!=str, HistoryOfPresentIllness)))/len(HistoryOfPresentIllness))\n",
    "traindata[\"ChiefComplaint\"] = ChiefComplaint\n",
    "traindata[\"HistoryOfPresentIllness\"] = HistoryOfPresentIllness\n",
    "traindata = traindata[(~traindata.ChiefComplaint.isna()) & (~traindata.HistoryOfPresentIllness.isna())].reset_index(drop=True)\n",
    "traindata.drop(columns=[\"text\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.to_csv(\"./data/mimic_train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M3ForInference(\n",
    "#   (model): XLMRobertaModel(\n",
    "#     (embeddings): XLMRobertaEmbeddings(\n",
    "#       (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
    "#       (position_embeddings): Embedding(8194, 1024, padding_idx=1)\n",
    "#       (token_type_embeddings): Embedding(1, 1024)\n",
    "#       (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
    "#       (dropout): Dropout(p=0.1, inplace=False)\n",
    "#     )\n",
    "#     (encoder): XLMRobertaEncoder(\n",
    "#       (layer): ModuleList(\n",
    "#         (0-23): 24 x XLMRobertaLayer(\n",
    "#           (attention): XLMRobertaAttention(\n",
    "#             (self): XLMRobertaSelfAttention(\n",
    "#               (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
    "#               (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
    "#               (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
    "#               (dropout): Dropout(p=0.1, inplace=False)\n",
    "#             )\n",
    "#             (output): XLMRobertaSelfOutput(\n",
    "#               (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
    "#               (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
    "#               (dropout): Dropout(p=0.1, inplace=False)\n",
    "#             )\n",
    "#           )\n",
    "#           (intermediate): XLMRobertaIntermediate(\n",
    "#             (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
    "#             (intermediate_act_fn): GELUActivation()\n",
    "#           )\n",
    "#           (output): XLMRobertaOutput(\n",
    "#             (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
    "#             (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
    "#             (dropout): Dropout(p=0.1, inplace=False)\n",
    "#           )\n",
    "#         )\n",
    "#       )\n",
    "#     )\n",
    "#     (pooler): XLMRobertaPooler(\n",
    "#       (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
    "#       (activation): Tanh()\n",
    "#     )\n",
    "#   )\n",
    "#   (cross_entropy): CrossEntropyLoss()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 疾病知识图谱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取mimic iv中疾病所需数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_disease = pd.read_csv(\"./raw_data/Diseases of the circulatory system.csv\", index_col=0)\n",
    "icd2name = pd.read_csv(\"./raw_data/d_icd_diagnoses.csv\")\n",
    "# 疾病当前的seq_num和最大的seq_num 算占比作为权重 计算嵌入向量\n",
    "id2icd = pd.read_csv(\"./raw_data/diagnosis_icd.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "循环系统疾病"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "      <th>seq_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11000566</td>\n",
       "      <td>28693615</td>\n",
       "      <td>B974</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11000566</td>\n",
       "      <td>28693615</td>\n",
       "      <td>I2699</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000566</td>\n",
       "      <td>28693615</td>\n",
       "      <td>D89813</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11000566</td>\n",
       "      <td>28693615</td>\n",
       "      <td>C9202</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11000566</td>\n",
       "      <td>28693615</td>\n",
       "      <td>T865</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id icd_code  icd_version  seq_num\n",
       "0    11000566  28693615     B974           10        1\n",
       "1    11000566  28693615    I2699           10        2\n",
       "2    11000566  28693615   D89813           10        3\n",
       "3    11000566  28693615    C9202           10        4\n",
       "4    11000566  28693615     T865           10        5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "used_disease = pd.merge(all_disease, id2icd, how='left')\n",
    "used_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_disease = pd.merge(used_disease, used_disease.groupby([\"subject_id\", \"hadm_id\"])[[\"seq_num\"]].max(), on=[\"subject_id\", \"hadm_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有81种疾病暂时没找到对应的icd10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd9to10 = pd.read_table(\"./raw_data/ICD9_to_ICD10_mapping.txt\", sep='\\t')\n",
    "icd9to10 = {a.replace('.', ''):b for a, b in zip(icd9to10['diagnosis_code'].tolist(), icd9to10['icd10cm'].tolist())}\n",
    "\n",
    "# res = used_disease[used_disease['icd_version']==9]['icd_code'].map(icd9to10)\n",
    "# len(set(used_disease.iloc[res[res.isna()].index]['icd_code'].tolist())), len(set(res.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换能找到对应icd10编码的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = used_disease[used_disease['icd_version']==9]['icd_code'].tolist()\n",
    "res = used_disease[used_disease['icd_version']==9]['icd_code'].map(icd9to10).tolist()\n",
    "\n",
    "used_disease.loc[used_disease['icd_version']==9, 'icd_code'] = [b if b!='NoDx' and pd.notna(b) else a for a,b in zip(origin, res)]\n",
    "used_disease.loc[used_disease['icd_version']==9, 'icd_version'] = [10 if i!='NoDx' and pd.notna(i) else 9 for i in res]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果没找到icd9对应的icd10也先保存原样了\n",
    "\n",
    "icd10中循环系统疾病为编号I开头的icd_code, 这里只筛选了icd-10的疾病数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>long_title</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>total_seq_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11000566</td>\n",
       "      <td>28693615</td>\n",
       "      <td>I2699</td>\n",
       "      <td>Other pulmonary embolism without acute cor pul...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>11000680</td>\n",
       "      <td>27035960</td>\n",
       "      <td>I120</td>\n",
       "      <td>Hypertensive chronic kidney disease with stage...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>11000722</td>\n",
       "      <td>24717411</td>\n",
       "      <td>I619</td>\n",
       "      <td>Nontraumatic intracerebral hemorrhage, unspeci...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>11000722</td>\n",
       "      <td>24717411</td>\n",
       "      <td>I97811</td>\n",
       "      <td>Intraoperative cerebrovascular infarction duri...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>11000743</td>\n",
       "      <td>24317015</td>\n",
       "      <td>I959</td>\n",
       "      <td>Hypotension, unspecified</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138192</th>\n",
       "      <td>13180748</td>\n",
       "      <td>28208689</td>\n",
       "      <td>I10</td>\n",
       "      <td>Essential (primary) hypertension</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138240</th>\n",
       "      <td>13180830</td>\n",
       "      <td>20263113</td>\n",
       "      <td>I2510</td>\n",
       "      <td>Atherosclerotic heart disease of native corona...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138242</th>\n",
       "      <td>13180830</td>\n",
       "      <td>20263113</td>\n",
       "      <td>I129</td>\n",
       "      <td>Hypertensive chronic kidney disease with stage...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138295</th>\n",
       "      <td>13181123</td>\n",
       "      <td>20624663</td>\n",
       "      <td>I10</td>\n",
       "      <td>Essential (primary) hypertension</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138346</th>\n",
       "      <td>13181123</td>\n",
       "      <td>21201632</td>\n",
       "      <td>I10</td>\n",
       "      <td>Essential (primary) hypertension</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162875 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         subject_id   hadm_id icd_code  \\\n",
       "1          11000566  28693615    I2699   \n",
       "57         11000680  27035960     I120   \n",
       "96         11000722  24717411     I619   \n",
       "97         11000722  24717411   I97811   \n",
       "126        11000743  24317015     I959   \n",
       "...             ...       ...      ...   \n",
       "4138192    13180748  28208689      I10   \n",
       "4138240    13180830  20263113    I2510   \n",
       "4138242    13180830  20263113     I129   \n",
       "4138295    13181123  20624663      I10   \n",
       "4138346    13181123  21201632      I10   \n",
       "\n",
       "                                                long_title  seq_num  \\\n",
       "1        Other pulmonary embolism without acute cor pul...        2   \n",
       "57       Hypertensive chronic kidney disease with stage...        3   \n",
       "96       Nontraumatic intracerebral hemorrhage, unspeci...        2   \n",
       "97       Intraoperative cerebrovascular infarction duri...        3   \n",
       "126                               Hypotension, unspecified        7   \n",
       "...                                                    ...      ...   \n",
       "4138192                   Essential (primary) hypertension        3   \n",
       "4138240  Atherosclerotic heart disease of native corona...        1   \n",
       "4138242  Hypertensive chronic kidney disease with stage...        3   \n",
       "4138295                   Essential (primary) hypertension        6   \n",
       "4138346                   Essential (primary) hypertension        2   \n",
       "\n",
       "         total_seq_num  \n",
       "1                   11  \n",
       "57                   8  \n",
       "96                   5  \n",
       "97                   5  \n",
       "126                 23  \n",
       "...                ...  \n",
       "4138192             10  \n",
       "4138240             10  \n",
       "4138242             10  \n",
       "4138295             11  \n",
       "4138346              3  \n",
       "\n",
       "[162875 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id2name = pd.merge(used_disease, icd2name, how='left')\n",
    "id2name = id2name[id2name['icd_version']==10][id2name[id2name['icd_version']==10]['icd_code'].map(lambda x: x.startswith('I'))].drop_duplicates()\n",
    "id2name = id2name[[\"subject_id\", \"hadm_id\", \"icd_code\", \"long_title\", \"seq_num_x\", \"seq_num_y\"]].rename(columns={\"seq_num_x\": \"seq_num\", \"seq_num_y\":\"total_seq_num\"})\n",
    "id2name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于60247就诊记录的162875条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162875, 60247)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(id2name), len(id2name[['subject_id', 'hadm_id']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2name.to_csv(\"./processed_data/subject_id_to_icd&name.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有疾病列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./processed_data/subject_id_to_icd&name.csv\")[['icd_code', 'long_title']].drop_duplicates()\n",
    "data = data.sort_values('icd_code')\n",
    "data.to_csv(\"./processed_data/all_disease.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建为所需数据文件格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取icd对应的主诉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "mimic_data = pd.read_csv(\"./data/mimic_train_data.csv\", usecols=['subject_id', 'hadm_id', 'ChiefComplaint'])\n",
    "icd_data = pd.read_csv(\"data/subject_id_to_icd&name.csv\", usecols=['subject_id', 'hadm_id', 'icd_code', 'seq_num', 'total_seq_num', 'long_title'])\n",
    "\n",
    "tmp = pd.merge(icd_data, mimic_data, on=['subject_id', 'hadm_id'])\n",
    "# tmp.head()\n",
    "\n",
    "res = defaultdict(list)\n",
    "for name, group in tqdm(tmp.groupby('icd_code')):\n",
    "    group = group[group['ChiefComplaint'].notna()]\n",
    "    for i in range(len(group)):\n",
    "        res[name].append({\"ChiefComplaint\": group.iloc[i]['ChiefComplaint'], 'weight': f\"{group.iloc[i]['seq_num']}/{group.iloc[i]['total_seq_num']}\"})\n",
    "\n",
    "with open(\"./data/icd2text.json\", 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[tmp[\"ChiefComplaint\"].notna()][['icd_code', 'long_title']].drop_duplicates().sort_values('icd_code').to_csv(\"./data/all_disease.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = tmp[\"icd_code\"].drop_duplicates().tolist()\n",
    "links = defaultdict(int)\n",
    "\n",
    "tmp = tmp[tmp[\"ChiefComplaint\"].notna()]\n",
    "for name, group in tmp.groupby(['subject_id', 'hadm_id']):\n",
    "    for comb in combinations(group['icd_code'].tolist(), 2):\n",
    "        links[tuple(sorted(comb))] += 1\n",
    "nodes = sorted(nodes)\n",
    "graph_data = {'nodes': [{'id': i, 'label': node} for i, node in enumerate(nodes)],\n",
    "              'links': [{'source': nodes.index(k[0]), 'target': nodes.index(k[1]), 'weight': v} for k, v in links.items()]}\n",
    "\n",
    "print(len(nodes), len(links.keys()))\n",
    "\n",
    "with open(\"./cache/disease_graph.json\", 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(graph_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按seq_num加权计算embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from tqdm.auto import tqdm\n",
    "from src.model.bgem3 import M3ForInference\n",
    "from src.utils.arguments import ModelArguments\n",
    "\n",
    "\n",
    "with open(\"./data/icd2text.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "args = ModelArguments(encode_sub_batch_size=-1)\n",
    "model = M3ForInference(args)\n",
    "\n",
    "with torch.no_grad():\n",
    "    res = []\n",
    "    for icd_code, v in tqdm(data.items()):\n",
    "        if len(v) > 1:\n",
    "            # (batch_size, 1)\n",
    "            weight = softmax(torch.tensor([1-eval(d[\"weight\"]) for d in v], device=\"cuda\"), dim=0).unsqueeze_(1)\n",
    "            # (batch_size, embed_dim)\n",
    "            embed = model([d[\"ChiefComplaint\"] for d in v])\n",
    "            res.append(torch.sum(embed * weight, dim=0))\n",
    "        else:\n",
    "            embed = model(v[0][\"ChiefComplaint\"])\n",
    "            res.append(embed)\n",
    "    res = torch.stack(res)\n",
    "    print(f\"embedding matrix shape: {res.shape}, node num: {len(data)}\")\n",
    "    torch.save(res, \"./data/disease_weight_embed.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按搜索结果计算embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.bgem3 import M3ForInference\n",
    "from src.utils.arguments import ModelArguments\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import json\n",
    "\n",
    "\n",
    "args = ModelArguments(encode_sub_batch_size=-1)\n",
    "model = M3ForInference(args)\n",
    "with torch.no_grad():\n",
    "    with open(\"./data/icd2text.json\", encoding='utf-8') as f:\n",
    "        data:dict = json.load(f)\n",
    "    res = []\n",
    "    for k,v in tqdm(data.items()):\n",
    "        res.append(model(\",\".join(v)).detach().to('cpu'))\n",
    "    res = torch.stack(v)\n",
    "    torch.save(res, \"./data/embeddings/disease_embed.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
